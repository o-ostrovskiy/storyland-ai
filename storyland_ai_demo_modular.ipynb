{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StoryLand AI - Modular Demo\n",
    "\n",
    "**Transform books into travel adventures using modular AI agents.**\n",
    "\n",
    "This notebook demonstrates the modular version of StoryLand AI, where agents, tools, and services are organized into reusable packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment Setup Complete\n",
      "   Google API Key: OK\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import uuid\n",
    "import logging\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Google ADK components\n",
    "from google.genai import types\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import Runner\n",
    "\n",
    "# Import from our modules\n",
    "from common.config import load_config\n",
    "from common.logging import setup_logger\n",
    "\n",
    "from services.session_service import create_session_service\n",
    "from services.memory_service import create_memory_service\n",
    "from services.context_manager import ContextManager\n",
    "\n",
    "from tools.google_books import google_books_tool\n",
    "from agents.orchestrator import create_workflow\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = setup_logger(\"storyland_demo\")\n",
    "\n",
    "print(\"✅ Environment Setup Complete\")\n",
    "print(f\"   Google API Key: {'OK' if os.getenv('GOOGLE_API_KEY') else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure your book and session settings here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: gone with the wind\n",
      "Author: Unknown\n",
      "Database: Disabled\n",
      "Memory: Disabled\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURE YOUR BOOK HERE\n",
    "# ============================================================\n",
    "BOOK_TITLE = \"gone with the wind\"\n",
    "AUTHOR = \"\"  # Optional - leave empty if unknown\n",
    "\n",
    "# Session configuration\n",
    "USE_DATABASE = False  # Set to True to use SQLite for persistent sessions\n",
    "USE_MEMORY = False    # Set to True to enable memory-based personalization\n",
    "USER_ID = \"user1\"\n",
    "# ============================================================\n",
    "\n",
    "print(f\"Book: {BOOK_TITLE}\")\n",
    "print(f\"Author: {AUTHOR or 'Unknown'}\")\n",
    "print(f\"Database: {'Enabled' if USE_DATABASE else 'Disabled'}\")\n",
    "print(f\"Memory: {'Enabled' if USE_MEMORY else 'Disabled'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Services\n",
    "\n",
    "Create the model, session service, and workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:32:57,448 - WARNING - google_adk.google.adk.runners - App name mismatch detected. The runner is configured with app name \"storyland\", but the root agent was loaded from \"/Users/osa/Documents/storyland/storyland-ai/.venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model configured: gemini-2.0-flash-lite\n",
      "Using InMemorySessionService (not persistent)\n",
      "✅ Session service created\n",
      "✅ Context manager created\n",
      "✅ Workflow created\n",
      "✅ Runner created\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = load_config()\n",
    "\n",
    "# Configure Gemini model\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,\n",
    "    exp_base=7,\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504]\n",
    ")\n",
    "\n",
    "model = Gemini(\n",
    "    model=config.model_name,\n",
    "    api_key=config.google_api_key,\n",
    "    retry_options=retry_config\n",
    ")\n",
    "\n",
    "print(f\"✅ Model configured: {model.model}\")\n",
    "\n",
    "# Create session service\n",
    "session_service = create_session_service(use_database=USE_DATABASE)\n",
    "print(\"✅ Session service created\")\n",
    "\n",
    "# Create memory service (if enabled)\n",
    "memory_service = None\n",
    "if USE_MEMORY:\n",
    "    memory_service = create_memory_service()\n",
    "    print(\"✅ Memory service created\")\n",
    "\n",
    "# Create context manager\n",
    "context_manager = ContextManager(max_events=20)\n",
    "print(\"✅ Context manager created\")\n",
    "\n",
    "# Create workflow\n",
    "workflow = create_workflow(model, google_books_tool)\n",
    "print(\"✅ Workflow created\")\n",
    "\n",
    "# Create runner\n",
    "runner = Runner(\n",
    "    agent=workflow,\n",
    "    app_name=\"storyland\",\n",
    "    session_service=session_service\n",
    ")\n",
    "print(\"✅ Runner created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Session created: ea03edf7...\n"
     ]
    }
   ],
   "source": [
    "# Create a new session\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "await session_service.create_session(\n",
    "    app_name=\"storyland\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=session_id,\n",
    "    state={\n",
    "        \"book_title\": BOOK_TITLE,\n",
    "        \"author\": AUTHOR,\n",
    "        # You can add user preferences here\n",
    "        \"user:preferences\": {\n",
    "            \"prefers_museums\": True,\n",
    "            \"budget\": \"moderate\",\n",
    "            \"pace\": \"moderate\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✅ Session created: {session_id[:8]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Workflow\n",
    "\n",
    "Run the multi-agent workflow to create the travel itinerary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:28,987 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXECUTING WORKFLOW\n",
      "======================================================================\n",
      "Book: gone with the wind\n",
      "Author: Unknown\n",
      "\n",
      "USER REQUEST:\n",
      "Create a literary travel itinerary for \"gone with the wind\" by unknown author.\n",
      "\n",
      "Execute all steps and return the complete combined results.\n",
      "\n",
      "Starting workflow execution...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:29,669 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:29,673 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-20 22:33:29,674 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:29,675 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] book_metadata_researcher\n",
      "\n",
      "✅ Workflow complete (1 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:30,377 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:30,383 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-20 22:33:30,389 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:30,390 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] book_metadata_formatter\n",
      "\n",
      "✅ Workflow complete (2 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:35,743 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:35,750 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-20 22:33:35,754 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:35,755 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] book_context_researcher\n",
      "\n",
      "✅ Workflow complete (3 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:36,671 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:36,676 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-20 22:33:36,680 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:36,681 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
      "2025-11-20 22:33:36,686 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:36,686 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
      "2025-11-20 22:33:36,693 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:36,694 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] book_context_formatter\n",
      "\n",
      "✅ Workflow complete (4 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:41,199 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:41,204 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-20 22:33:41,211 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:41,212 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] author_researcher\n",
      "\n",
      "✅ Workflow complete (5 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:45,091 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:45,098 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-20 22:33:45,102 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:45,104 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
      "2025-11-20 22:33:45,178 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:45,182 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-20 22:33:45,185 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:45,185 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] city_researcher\n",
      "\n",
      "✅ Workflow complete (6 events)\n",
      "[7] landmark_researcher\n",
      "\n",
      "✅ Workflow complete (7 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:45,339 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-20 22:33:45,341 - INFO - google_genai._api_client - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.5109296445475264 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}.\n",
      "2025-11-20 22:33:45,363 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-20 22:33:45,365 - INFO - google_genai._api_client - Retrying google.genai._api_client.BaseApiClient._async_request_once in 1.4498744474389957 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}.\n",
      "2025-11-20 22:33:47,035 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-20 22:33:47,038 - INFO - google_genai._api_client - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.9823153915787275 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}.\n",
      "2025-11-20 22:33:47,039 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-11-20 22:33:47,042 - INFO - google_genai._api_client - Retrying google.genai._api_client.BaseApiClient._async_request_once in 7.714722319408718 seconds as it raised ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}.\n",
      "2025-11-20 22:33:48,330 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:48,334 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] author_formatter\n",
      "\n",
      "✅ Workflow complete (8 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:57,010 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:57,016 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] city_formatter\n",
      "\n",
      "✅ Workflow complete (9 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:33:57,583 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:33:57,586 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-20 22:33:57,590 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-20 22:33:57,590 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] landmark_formatter\n",
      "\n",
      "✅ Workflow complete (10 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 22:34:03,731 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-20 22:34:03,738 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] trip_composer\n",
      "\n",
      "✅ Workflow complete (11 events)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXECUTING WORKFLOW\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Book: {BOOK_TITLE}\")\n",
    "print(f\"Author: {AUTHOR or 'Unknown'}\\n\")\n",
    "\n",
    "# Create the prompt\n",
    "prompt = f\"\"\"Create a literary travel itinerary for \"{BOOK_TITLE}\" by {AUTHOR or 'unknown author'}.\n",
    "\n",
    "Execute all steps and return the complete combined results.\"\"\"\n",
    "\n",
    "user_message = types.Content(\n",
    "    role='user',\n",
    "    parts=[types.Part(text=prompt)]\n",
    ")\n",
    "\n",
    "print(f\"USER REQUEST:\")\n",
    "print(f\"{prompt}\\n\")\n",
    "print(\"Starting workflow execution...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run workflow and collect results\n",
    "final_response = None\n",
    "event_count = 0\n",
    "\n",
    "async for event in runner.run_async(\n",
    "    user_id=USER_ID,\n",
    "    session_id=session_id,\n",
    "    new_message=user_message\n",
    "):\n",
    "    event_count += 1\n",
    "    \n",
    "    # Show progress\n",
    "    if event.author:\n",
    "        print(f\"[{event_count}] {event.author}\")\n",
    "    \n",
    "    if event.is_final_response():\n",
    "        final_response = event\n",
    "        print(f\"\\n✅ Workflow complete ({event_count} events)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAVEL ITINERARY - 3 Cities\n",
      "======================================================================\n",
      "\n",
      "City #1: Atlanta, USA\n",
      "Days suggested: 3\n",
      "\n",
      "Overview: Immerse yourself in the world of \"Gone with the Wind\" in Atlanta, the heart of the story. Explore the city's historical sites, tracing the steps of Scarlett O'Hara and witnessing the transformation of the South during the Civil War and Reconstruction eras. Discover the places that inspired the novel and film, and experience the era's atmosphere.\n",
      "\n",
      "Stops (5):\n",
      "  1. Margaret Mitchell House (museum)\n",
      "     This is where Margaret Mitchell wrote \"Gone with the Wind\". Step into the rooms where the story came to life, and gain insight into the author's creative process.\n",
      "  2. Atlanta History Center (museum)\n",
      "     Explore Civil War exhibits and view the Margaret Mitchell House, offering a comprehensive view of the era and the author's legacy.\n",
      "  3. Historic Oakland Cemetery (cemetery)\n",
      "     Visit the final resting place of Margaret Mitchell. Reflect on the story while strolling through the historic grounds.\n",
      "  4. Georgian Terrace Hotel (hotel)\n",
      "     Experience a touch of glamour where the premiere after-party for \"Gone with the Wind\" was held, attended by the stars.\n",
      "  5. Ansley Park (neighborhood)\n",
      "     See the area where Margaret Mitchell was born and spent her later years, providing a glimpse into her life.\n",
      "\n",
      "City #2: Jonesboro, USA\n",
      "Days suggested: 1\n",
      "\n",
      "Overview: Journey to Jonesboro, the inspiration for Tara, the O'Hara plantation. Explore the Road to Tara Museum, and envision the iconic setting of the novel, connecting with the heart of the story.\n",
      "\n",
      "Stops (1):\n",
      "  1. Road to Tara Museum (museum)\n",
      "     Discover memorabilia from the book and movie, immersing yourself in the world of \"Gone with the Wind\".\n",
      "\n",
      "City #3: Marietta, USA\n",
      "Days suggested: 1\n",
      "\n",
      "Overview: Visit Marietta, home to the \"Gone with the Wind Museum.\" Explore costumes, promotional material, and other items related to the film adaptation.\n",
      "\n",
      "Stops (1):\n",
      "  1. Marietta Gone With The Wind Museum (museum)\n",
      "     View Scarlett's honeymoon gown and original promotional material, gaining insight into the beloved film.\n",
      "\n",
      "======================================================================\n",
      "TRIP SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Embark on a literary journey through the heart of the American South with \"Gone with the Wind.\" Explore Atlanta, Jonesboro, and Marietta, immersing yourself in the book's key settings. Discover the places where Margaret Mitchell lived and wrote, and the sites that inspired the story. This trip is your chance to step into the world of Scarlett O'Hara and experience the enduring saga firsthand.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract result from final response\n",
    "result_data = {}\n",
    "if final_response and final_response.content and final_response.content.parts:\n",
    "    for part in final_response.content.parts:\n",
    "        if hasattr(part, 'text') and part.text:\n",
    "            json_start = part.text.find('{')\n",
    "            json_end = part.text.rfind('}') + 1\n",
    "            \n",
    "            if json_start >= 0 and json_end > json_start:\n",
    "                try:\n",
    "                    result_data = json.loads(part.text[json_start:json_end])\n",
    "                    break\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(f\"Failed to parse JSON: {e}\")\n",
    "\n",
    "# Display the itinerary\n",
    "cities_list = result_data.get('cities', [])\n",
    "\n",
    "if cities_list:\n",
    "    print(f\"\\nTRAVEL ITINERARY - {len(cities_list)} Cities\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, city_plan in enumerate(cities_list, 1):\n",
    "        print(f\"\\nCity #{i}: {city_plan.get('name')}, {city_plan.get('country')}\")\n",
    "        print(f\"Days suggested: {city_plan.get('days_suggested', 1)}\")\n",
    "        \n",
    "        if city_plan.get('overview'):\n",
    "            print(f\"\\nOverview: {city_plan.get('overview')}\")\n",
    "        \n",
    "        stops = city_plan.get('stops', [])\n",
    "        if stops:\n",
    "            print(f\"\\nStops ({len(stops)}):\")\n",
    "            for j, stop in enumerate(stops, 1):\n",
    "                print(f\"  {j}. {stop.get('name')} ({stop.get('type')})\")\n",
    "                print(f\"     {stop.get('reason')}\")\n",
    "    \n",
    "    # Summary\n",
    "    summary_text = result_data.get('summary_text')\n",
    "    if summary_text:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRIP SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\n{summary_text}\\n\")\n",
    "else:\n",
    "    print(\"\\n❌ No itinerary data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Memory (Optional)\n",
    "\n",
    "If memory is enabled, save this session for future personalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️  Memory service not enabled\n"
     ]
    }
   ],
   "source": [
    "if memory_service:\n",
    "    # Get the full session\n",
    "    session = await session_service.get_session(\n",
    "        app_name=\"storyland\",\n",
    "        user_id=USER_ID,\n",
    "        session_id=session_id\n",
    "    )\n",
    "    \n",
    "    # Add to memory\n",
    "    await memory_service.add_session_to_memory(session)\n",
    "    print(\"✅ Session added to memory for future personalization\")\n",
    "    \n",
    "    # Test memory search\n",
    "    memory_results = await memory_service.search_memory(\n",
    "        app_name=\"storyland\",\n",
    "        user_id=USER_ID,\n",
    "        query=\"travel preferences\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nMemory search found {len(memory_results.memories)} relevant memories\")\n",
    "else:\n",
    "    print(\"ℹ️  Memory service not enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the modular architecture:\n",
    "\n",
    "- **Models** ([models/](models/)) - Pydantic data structures\n",
    "- **Tools** ([tools/](tools/)) - External API integrations\n",
    "- **Agents** ([agents/](agents/)) - Specialized AI agents\n",
    "- **Services** ([services/](services/)) - Session, memory, and context management\n",
    "- **Config** ([common/config.py](common/config.py)) - Centralized configuration\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Try the CLI**: `python main.py \"your book title\" --author \"Author Name\"`\n",
    "2. **Enable persistence**: Set `USE_DATABASE=true` in `.env`\n",
    "3. **Enable memory**: Set `USE_MEMORY=true` in `.env`\n",
    "4. **Customize agents**: Edit files in [agents/](agents/) directory\n",
    "5. **Add new tools**: Create new tools in [tools/](tools/) directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
