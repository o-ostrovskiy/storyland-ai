{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StoryLand AI - Modular Demo\n",
    "\n",
    "**Transform books into travel adventures using modular AI agents.**\n",
    "\n",
    "This notebook demonstrates the modular version of StoryLand AI, where agents, tools, and services are organized into reusable packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Setup Complete\n",
      "   Google API Key: OK\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import uuid\n",
    "import logging\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Google ADK components\n",
    "from google.genai import types\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import Runner\n",
    "\n",
    "# Import from our modules\n",
    "from common.config import load_config\n",
    "from common.logging import setup_logger\n",
    "\n",
    "from services.session_service import create_session_service\n",
    "from services.context_manager import ContextManager\n",
    "\n",
    "from tools.google_books import google_books_tool\n",
    "from agents.orchestrator import create_workflow\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = setup_logger(\"storyland_demo\")\n",
    "\n",
    "print(\"Environment Setup Complete\")\n",
    "print(f\"   Google API Key: {'OK' if os.getenv('GOOGLE_API_KEY') else 'MISSING'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure your book and session settings here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: gone with the wind\n",
      "Author: Unknown\n",
      "Database: Disabled\n",
      "Preferences: {'budget': 'moderate', 'preferred_pace': 'moderate', 'prefers_museums': True, 'travels_with_kids': False}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURE YOUR BOOK HERE\n",
    "# ============================================================\n",
    "BOOK_TITLE = \"gone with the wind\"\n",
    "AUTHOR = \"\"  # Optional - leave empty if unknown\n",
    "\n",
    "# Session configuration\n",
    "USE_DATABASE = False  # Set to True to use SQLite for persistent sessions\n",
    "USER_ID = \"user1\"\n",
    "\n",
    "# User preferences (used for personalization)\n",
    "USER_PREFERENCES = {\n",
    "    \"budget\": \"moderate\",          # budget, moderate, luxury\n",
    "    \"preferred_pace\": \"moderate\",  # relaxed, moderate, fast-paced\n",
    "    \"prefers_museums\": True,\n",
    "    \"travels_with_kids\": False,\n",
    "}\n",
    "# ============================================================\n",
    "\n",
    "print(f\"Book: {BOOK_TITLE}\")\n",
    "print(f\"Author: {AUTHOR or 'Unknown'}\")\n",
    "print(f\"Database: {'Enabled' if USE_DATABASE else 'Disabled'}\")\n",
    "print(f\"Preferences: {USER_PREFERENCES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Services\n",
    "\n",
    "Create the model, session service, and workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:44,353 - WARNING - google_adk.google.adk.runners - App name mismatch detected. The runner is configured with app name \"storyland\", but the root agent was loaded from \"/Users/osa/Documents/storyland/storyland-ai/.venv/lib/python3.12/site-packages/google/adk/agents\", which implies app name \"agents\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configured: gemini-2.0-flash-lite\n",
      "Using InMemorySessionService (not persistent)\n",
      "Session service created\n",
      "Context manager created\n",
      "Workflow created\n",
      "Runner created\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = load_config()\n",
    "\n",
    "# Configure Gemini model\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,\n",
    "    exp_base=7,\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504]\n",
    ")\n",
    "\n",
    "model = Gemini(\n",
    "    model=config.model_name,\n",
    "    api_key=config.google_api_key,\n",
    "    retry_options=retry_config\n",
    ")\n",
    "\n",
    "print(f\"Model configured: {model.model}\")\n",
    "\n",
    "# Create session service\n",
    "session_service = create_session_service(use_database=USE_DATABASE)\n",
    "print(\"Session service created\")\n",
    "\n",
    "# Create context manager\n",
    "context_manager = ContextManager(max_events=20)\n",
    "print(\"Context manager created\")\n",
    "\n",
    "# Create workflow\n",
    "workflow = create_workflow(model, google_books_tool)\n",
    "print(\"Workflow created\")\n",
    "\n",
    "# Create runner\n",
    "runner = Runner(\n",
    "    agent=workflow,\n",
    "    app_name=\"storyland\",\n",
    "    session_service=session_service\n",
    ")\n",
    "print(\"Runner created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created: 06cf9cc4...\n",
      "Preferences stored in state['user:preferences']\n"
     ]
    }
   ],
   "source": [
    "# Create a new session\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "await session_service.create_session(\n",
    "    app_name=\"storyland\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=session_id,\n",
    "    state={\n",
    "        \"book_title\": BOOK_TITLE,\n",
    "        \"author\": AUTHOR,\n",
    "        # User preferences - accessed by reader_profile_agent via get_preferences_tool\n",
    "        \"user:preferences\": USER_PREFERENCES\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Session created: {session_id[:8]}...\")\n",
    "print(f\"Preferences stored in state['user:preferences']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Workflow\n",
    "\n",
    "Run the multi-agent workflow to create the travel itinerary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:44,378 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXECUTING WORKFLOW\n",
      "======================================================================\n",
      "Book: gone with the wind\n",
      "Author: Unknown\n",
      "\n",
      "USER REQUEST:\n",
      "Create a literary travel itinerary for \"gone with the wind\" by unknown author.\n",
      "\n",
      "Execute all steps and return the complete combined results.\n",
      "\n",
      "Starting workflow execution...\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:45,034 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:40:45,039 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:40:45,041 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:40:45,042 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] book_metadata_researcher\n",
      "\n",
      "✅ Workflow complete (1 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:46,103 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:40:46,109 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:40:46,112 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:40:46,114 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] book_metadata_formatter\n",
      "\n",
      "✅ Workflow complete (2 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:51,674 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:40:51,680 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:40:51,685 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:40:51,686 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] book_context_researcher\n",
      "\n",
      "✅ Workflow complete (3 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:52,620 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:40:52,623 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:40:52,628 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] book_context_formatter\n",
      "\n",
      "✅ Workflow complete (4 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:53,103 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:40:53,108 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:40:53,111 - WARNING - google_genai.types - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-11-22 14:40:53,116 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] reader_profile_agent\n",
      "[6] reader_profile_agent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:53,616 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:40:53,621 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:40:53,625 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:40:53,627 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
      "2025-11-22 14:40:53,635 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:40:53,636 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
      "2025-11-22 14:40:53,641 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:40:53,646 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] reader_profile_agent\n",
      "\n",
      "✅ Workflow complete (7 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:59,452 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:40:59,457 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:40:59,463 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:40:59,464 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] landmark_researcher\n",
      "\n",
      "✅ Workflow complete (8 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:40:59,842 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:40:59,848 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:40:59,851 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:40:59,852 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] author_researcher\n",
      "\n",
      "✅ Workflow complete (9 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:41:01,014 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:41:01,016 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] author_formatter\n",
      "\n",
      "✅ Workflow complete (10 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:41:01,397 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:41:01,401 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] landmark_formatter\n",
      "\n",
      "✅ Workflow complete (11 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:41:02,141 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:41:02,148 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:41:02,152 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:41:02,153 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12] city_researcher\n",
      "\n",
      "✅ Workflow complete (12 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:41:04,534 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:41:04,538 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n",
      "2025-11-22 14:41:04,543 - INFO - google_adk.google.adk.models.google_llm - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\n",
      "2025-11-22 14:41:04,544 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13] city_formatter\n",
      "\n",
      "✅ Workflow complete (13 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-22 14:41:10,205 - INFO - httpx - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-11-22 14:41:10,210 - INFO - google_adk.google.adk.models.google_llm - Response received from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] trip_composer\n",
      "\n",
      "✅ Workflow complete (14 events)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXECUTING WORKFLOW\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Book: {BOOK_TITLE}\")\n",
    "print(f\"Author: {AUTHOR or 'Unknown'}\\n\")\n",
    "\n",
    "# Create the prompt\n",
    "prompt = f\"\"\"Create a literary travel itinerary for \"{BOOK_TITLE}\" by {AUTHOR or 'unknown author'}.\n",
    "\n",
    "Execute all steps and return the complete combined results.\"\"\"\n",
    "\n",
    "user_message = types.Content(\n",
    "    role='user',\n",
    "    parts=[types.Part(text=prompt)]\n",
    ")\n",
    "\n",
    "print(f\"USER REQUEST:\")\n",
    "print(f\"{prompt}\\n\")\n",
    "print(\"Starting workflow execution...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Run workflow and collect results\n",
    "final_response = None\n",
    "event_count = 0\n",
    "\n",
    "async for event in runner.run_async(\n",
    "    user_id=USER_ID,\n",
    "    session_id=session_id,\n",
    "    new_message=user_message\n",
    "):\n",
    "    event_count += 1\n",
    "    \n",
    "    # Show progress\n",
    "    if event.author:\n",
    "        print(f\"[{event_count}] {event.author}\")\n",
    "    \n",
    "    if event.is_final_response():\n",
    "        final_response = event\n",
    "        print(f\"\\n✅ Workflow complete ({event_count} events)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAVEL ITINERARY - 3 Cities\n",
      "======================================================================\n",
      "\n",
      "City #1: Atlanta, USA\n",
      "Days suggested: 2\n",
      "\n",
      "Overview: Immerse yourself in the heart of the Gone With The Wind story in Atlanta, the city that serves as a pivotal backdrop to the novel. Explore the places that shaped Margaret Mitchell's life and the Civil War-era atmosphere.\n",
      "\n",
      "Stops (4):\n",
      "  1. Margaret Mitchell House and Museum (museum)\n",
      "     This is where Margaret Mitchell penned much of the novel. The museum offers an intimate look into her life and the creation of the epic.\n",
      "  2. Oakland Cemetery (cemetery)\n",
      "     Pay your respects at the final resting place of Margaret Mitchell, gaining a moment of reflection.\n",
      "  3. Mary Mac's Tea Room (restaurant)\n",
      "     Enjoy a meal at this iconic Southern restaurant, savoring classic dishes amidst historic ambiance.\n",
      "  4. Atlanta History Center (museum)\n",
      "     Explore the Civil War exhibit, to understand the historical context.\n",
      "\n",
      "City #2: Clayton County, USA\n",
      "Days suggested: 1\n",
      "\n",
      "Overview: Venture into Clayton County, the landscape that inspired the iconic Tara plantation. Discover the heart of the novel's setting and experience the charm of the South.\n",
      "\n",
      "Stops (2):\n",
      "  1. Road to Tara Museum (museum)\n",
      "     Explore the world of GWTW and see props and memorabillia from the film.\n",
      "  2. Stately Oaks Plantation (landmark)\n",
      "     Experience what the actual location of Tara may have looked like.\n",
      "\n",
      "City #3: Marietta, USA\n",
      "Days suggested: 1\n",
      "\n",
      "Overview: A nearby location that also has significant connections to the story, with a museum dedicated to the novel.\n",
      "\n",
      "Stops (1):\n",
      "  1. Marietta Gone With the Wind Museum (museum)\n",
      "     Discover a unique collection of GWTW memorabilia.\n",
      "\n",
      "======================================================================\n",
      "TRIP SUMMARY\n",
      "======================================================================\n",
      "\n",
      "This literary journey through the heart of Gone With the Wind offers a moderate-paced exploration of the key settings in Atlanta and Clayton County, with a detour to Marietta. Designed with your preference for museums in mind, the itinerary highlights key locations from the book and film adaptation, immersing you in the world of Scarlett O'Hara and the American South. The trip will bring the novel to life and give you a unique chance to experience the essence of the novel!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract result from final response\n",
    "result_data = {}\n",
    "if final_response and final_response.content and final_response.content.parts:\n",
    "    for part in final_response.content.parts:\n",
    "        if hasattr(part, 'text') and part.text:\n",
    "            json_start = part.text.find('{')\n",
    "            json_end = part.text.rfind('}') + 1\n",
    "            \n",
    "            if json_start >= 0 and json_end > json_start:\n",
    "                try:\n",
    "                    result_data = json.loads(part.text[json_start:json_end])\n",
    "                    break\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(f\"Failed to parse JSON: {e}\")\n",
    "\n",
    "# Display the itinerary\n",
    "cities_list = result_data.get('cities', [])\n",
    "\n",
    "if cities_list:\n",
    "    print(f\"\\nTRAVEL ITINERARY - {len(cities_list)} Cities\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, city_plan in enumerate(cities_list, 1):\n",
    "        print(f\"\\nCity #{i}: {city_plan.get('name')}, {city_plan.get('country')}\")\n",
    "        print(f\"Days suggested: {city_plan.get('days_suggested', 1)}\")\n",
    "        \n",
    "        if city_plan.get('overview'):\n",
    "            print(f\"\\nOverview: {city_plan.get('overview')}\")\n",
    "        \n",
    "        stops = city_plan.get('stops', [])\n",
    "        if stops:\n",
    "            print(f\"\\nStops ({len(stops)}):\")\n",
    "            for j, stop in enumerate(stops, 1):\n",
    "                print(f\"  {j}. {stop.get('name')} ({stop.get('type')})\")\n",
    "                print(f\"     {stop.get('reason')}\")\n",
    "    \n",
    "    # Summary\n",
    "    summary_text = result_data.get('summary_text')\n",
    "    if summary_text:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TRIP SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"\\n{summary_text}\\n\")\n",
    "else:\n",
    "    print(\"\\n❌ No itinerary data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Statistics\n",
    "\n",
    "Check the session context and token usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Statistics\n",
      "========================================\n",
      "Total events: 15\n",
      "Estimated tokens: 4174\n",
      "Within limit: True\n",
      "Should compact: False\n",
      "\n",
      "User Preferences in State:\n",
      "  budget: moderate\n",
      "  preferred_pace: moderate\n",
      "  prefers_museums: True\n",
      "  travels_with_kids: False\n"
     ]
    }
   ],
   "source": [
    "# Get the session to check context\n",
    "session = await session_service.get_session(\n",
    "    app_name=\"storyland\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=session_id\n",
    ")\n",
    "\n",
    "# Get context statistics\n",
    "stats = context_manager.get_context_stats(session.events)\n",
    "\n",
    "print(\"Context Statistics\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Total events: {stats['num_events']}\")\n",
    "print(f\"Estimated tokens: {stats['estimated_tokens']}\")\n",
    "print(f\"Within limit: {stats['within_limit']}\")\n",
    "print(f\"Should compact: {context_manager.should_compact(session.events)}\")\n",
    "\n",
    "# Show preferences from state\n",
    "prefs = session.state.get(\"user:preferences\", {})\n",
    "print(f\"\\nUser Preferences in State:\")\n",
    "for key, value in prefs.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the modular architecture:\n",
    "\n",
    "- **Models** ([models/](models/)) - Pydantic data structures\n",
    "- **Tools** ([tools/](tools/)) - External API integrations (Google Books, preferences)\n",
    "- **Agents** ([agents/](agents/)) - Specialized AI agents\n",
    "- **Services** ([services/](services/)) - Session and context management\n",
    "- **Config** ([common/config.py](common/config.py)) - Centralized configuration\n",
    "\n",
    "### How Preferences Work\n",
    "\n",
    "1. **Set preferences** in `USER_PREFERENCES` dict above\n",
    "2. **Stored in session state** as `user:preferences`\n",
    "3. **`reader_profile_agent`** calls `get_preferences_tool` to read from `ToolContext.state`\n",
    "4. **`trip_composer`** sees the preferences summary and personalizes the itinerary\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Try the CLI**: `python main.py \"your book title\" --budget luxury --pace relaxed`\n",
    "2. **Enable persistence**: Set `USE_DATABASE=True` above\n",
    "3. **Customize preferences**: Edit `USER_PREFERENCES` dict\n",
    "4. **Add new agents**: Edit files in [agents/](agents/) directory\n",
    "5. **Add new tools**: Create new tools in [tools/](tools/) directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
